{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_ANN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mazispider/ML_ANN/blob/master/Simple_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WpFtvohmf4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "c953a864-92e3-46d6-bdd1-973c6286945c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Seed the random number generator\n",
        "        np.random.seed(1)\n",
        "\n",
        "        # Set synaptic weights to a 3x1 matrix,\n",
        "        # with values from -1 to 1 and mean 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"\n",
        "        Takes in weighted sum of the inputs and normalizes\n",
        "        them through between 0 and 1 through a sigmoid function\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        \"\"\"\n",
        "        The derivative of the sigmoid function used to\n",
        "        calculate necessary weight adjustments\n",
        "        \"\"\"\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \"\"\"\n",
        "        We train the model through trial and error, adjusting the\n",
        "        synaptic weights each time to get a better result\n",
        "        \"\"\"\n",
        "        for iteration in range(training_iterations):\n",
        "            # Pass training set through the neural network\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            # Calculate the error rate\n",
        "            error = training_outputs - output\n",
        "\n",
        "            # Multiply error by input and gradient of the sigmoid function\n",
        "            # Less confident weights are adjusted more through the nature of the function\n",
        "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
        "\n",
        "            # Adjust synaptic weights\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        \"\"\"\n",
        "        Pass inputs through the neural network to get output\n",
        "        \"\"\"\n",
        "        \n",
        "        inputs = inputs.astype(float)\n",
        "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Initialize the single neuron neural network\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Random starting synaptic weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    # The training set, with 4 examples consisting of 3\n",
        "    # input values and 1 output value\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                                [1,1,1],\n",
        "                                [1,0,1],\n",
        "                                [0,1,1]])\n",
        "\n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    # Train the neural network\n",
        "    neural_network.train(training_inputs, training_outputs, 10000)\n",
        "\n",
        "    print(\"Synaptic weights after training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    A = str(input(\"Input 1: \"))\n",
        "    B = str(input(\"Input 2: \"))\n",
        "    C = str(input(\"Input 3: \"))\n",
        "    \n",
        "    print(\"New situation: input data = \", A, B, C)\n",
        "    print(\"Output data: \")\n",
        "    print(neural_network.think(np.array([A, B, C])))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random starting synaptic weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Synaptic weights after training: \n",
            "[[ 9.67299303]\n",
            " [-0.2078435 ]\n",
            " [-4.62963669]]\n",
            "Input 1: 1\n",
            "Input 2: 1\n",
            "Input 3: 0\n",
            "New situation: input data =  1 1 0\n",
            "Output data: \n",
            "[0.9999225]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}